{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "FO4He6AuvCvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b550075-b1b0-4b3a-8869-204dd86627d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 28 01:48:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    51W / 400W |   1067MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade  textblob gensim pytorch-nlp swifter\n"
      ],
      "metadata": {
        "id": "qT84LO_ryWGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb22fe7-f7df-4839-9b06-9349accd023b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: swifter in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-nlp) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.10/dist-packages (from swifter) (5.9.5)\n",
            "Requirement already satisfied: dask[dataframe]>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (2023.8.1)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (23.2)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (6.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2023.3.post1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter) (3.17.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.0->swifter) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import sys\n",
        "from textblob import TextBlob, Word\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import swifter\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import warnings\n",
        "import nltk\n",
        "\n",
        "max_length = 100\n",
        "# Hyperparameters\n",
        "embedding_dim = 100  # embedding dimension\n",
        "hidden_dim = 100  # LSTM hidden dimensions\n",
        "num_layers = 1  # number of LSTM layers\n",
        "batch_size = 64  # batch size\n",
        "num_epochs = 10  # number of epochs to train\n",
        "lr = 0.001  # learning rate\n",
        "\n",
        "\n",
        "def set_seeds_and_trace():\n",
        "  os.environ['PYTHONHASHSEED'] = '0'\n",
        "  np.random.seed(42)\n",
        "  random.seed(42)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "set_seeds_and_trace()\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('punkt')\n",
        "textblob_tokenizer = lambda x: TextBlob(x).words\n"
      ],
      "metadata": {
        "id": "6h9-CflyyWIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036f7adb-71fd-4f5d-cbb0-99cdb17eff81"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f ner_dataset.csv ]; then\n",
        "  wget -O ner_dataset.csv https://www.dropbox.com/s/mbfv0x988mdj89h/ner_dataset.csv?dl=0\n",
        "fi\n"
      ],
      "metadata": {
        "id": "0oENn5_JyWLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf13b8e-ab9f-4415-90e9-b4962b31dfc5"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh"
      ],
      "metadata": {
        "id": "CkxCOJz_yWNu"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv(\"./ner_dataset.csv\",encoding=\"latin1\")\n",
        "data = data.fillna(method='ffill')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "18V5m92oyWQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "73e81c9e-4d85-4cf5-e802-c89cd733828c"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0349c12e-ae0f-4879-a8d0-244d31978715\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0349c12e-ae0f-4879-a8d0-244d31978715')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0349c12e-ae0f-4879-a8d0-244d31978715 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0349c12e-ae0f-4879-a8d0-244d31978715');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9104fbc5-fb38-4453-9490-5d3ccab28dcf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9104fbc5-fb38-4453-9490-5d3ccab28dcf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9104fbc5-fb38-4453-9490-5d3ccab28dcf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique Words in corpus:\",data['Word'].nunique())\n",
        "print(\"Unique Tag in corpus:\",data['Tag'].nunique())"
      ],
      "metadata": {
        "id": "8RzRPJPTyWS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5ea133-789f-4457-8d8a-b7b9f7bc2c2d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Words in corpus: 35178\n",
            "Unique Tag in corpus: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(set(data['Word'].values))\n",
        "words.append(\"ENDPAD\")\n",
        "num_words = len(words)\n",
        "tags = list(set(data['Tag'].values))\n",
        "num_tags = len(tags)"
      ],
      "metadata": {
        "id": "oYF9u8Dp13YW"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceGetter(object):\n",
        "  def __init__(self,data):\n",
        "    self.n_sent = 1 #counter\n",
        "    self.data = data\n",
        "    agg_func = lambda s:[(w,p,t) for w,p,t in zip(s['Word'].tolist(),s['POS'].tolist(),s['Tag'].tolist())]\n",
        "    self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "    self.sentences = [s for s in self.grouped]\n",
        "\n",
        "\n",
        "\n",
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences"
      ],
      "metadata": {
        "id": "1XAv4P3G1-7D"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "id": "9tP7TzZ71-9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a04766-88d7-44ae-8a43-8c51e34ab64d"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'NNS', 'O'),\n",
              " ('of', 'IN', 'O'),\n",
              " ('demonstrators', 'NNS', 'O'),\n",
              " ('have', 'VBP', 'O'),\n",
              " ('marched', 'VBN', 'O'),\n",
              " ('through', 'IN', 'O'),\n",
              " ('London', 'NNP', 'B-geo'),\n",
              " ('to', 'TO', 'O'),\n",
              " ('protest', 'VB', 'O'),\n",
              " ('the', 'DT', 'O'),\n",
              " ('war', 'NN', 'O'),\n",
              " ('in', 'IN', 'O'),\n",
              " ('Iraq', 'NNP', 'B-geo'),\n",
              " ('and', 'CC', 'O'),\n",
              " ('demand', 'VB', 'O'),\n",
              " ('the', 'DT', 'O'),\n",
              " ('withdrawal', 'NN', 'O'),\n",
              " ('of', 'IN', 'O'),\n",
              " ('British', 'JJ', 'B-gpe'),\n",
              " ('troops', 'NNS', 'O'),\n",
              " ('from', 'IN', 'O'),\n",
              " ('that', 'DT', 'O'),\n",
              " ('country', 'NN', 'O'),\n",
              " ('.', '.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx =  {w : i+1 for i,w in enumerate(words)}\n",
        "tag2idx  =  {t : i for i,t in enumerate(tags)}"
      ],
      "metadata": {
        "id": "R4IPXmOQ1_Ci"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [[word2idx[w[0]] for w in s]for s in sentences]\n",
        "\n",
        "tokenized_sentences[0]"
      ],
      "metadata": {
        "id": "0ox9i1Zc1_FN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b3ebed-53e3-486d-8299-eef1f001d577"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29596,\n",
              " 25251,\n",
              " 21031,\n",
              " 16530,\n",
              " 34066,\n",
              " 417,\n",
              " 28589,\n",
              " 23689,\n",
              " 15978,\n",
              " 16447,\n",
              " 31340,\n",
              " 32557,\n",
              " 14364,\n",
              " 4705,\n",
              " 24470,\n",
              " 16447,\n",
              " 18025,\n",
              " 25251,\n",
              " 26566,\n",
              " 3620,\n",
              " 9597,\n",
              " 1579,\n",
              " 13191,\n",
              " 19103]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maximum_length = max([len(x) for x in tokenized_sentences])\n",
        "maximum_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etE_inANTDNU",
        "outputId": "9449fa46-2634-4b1e-8430-f3e29ea86f4d"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_X = [F.pad(torch.tensor(x), (0, maximum_length-len(x)), \"constant\", 0) for x in tokenized_sentences]\n",
        "X = torch.stack(pre_X)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ6-h8kASMdD",
        "outputId": "2dfadf23-afad-4fe8-c7b9-6969b5c54691"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([47959, 104])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_entities = [[tag2idx[w[2]] for w in s]for s in sentences]\n",
        "tokenizer_entities[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9qYXIGYR87O",
        "outputId": "56aa124a-459a-4443-eb5c-ba54f73640ae"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 7,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 7,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 9,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 16,\n",
              " 16]"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maximum_tag_length = max([len(y) for y in tokenizer_entities])\n",
        "maximum_tag_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9YKRkANT1Qi",
        "outputId": "5ffed519-be08-4094-c5d2-b46f66c6f6fb"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.pad(torch.tensor(tokenizer_entities[0]), (0, maximum_tag_length-len(tokenizer_entities[0])), \"constant\", tag2idx[\"O\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpC7xBQ3UfCj",
        "outputId": "2e6f452f-d920-4492-8e8f-49c5a1acf42f"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([16, 16, 16, 16, 16, 16,  7, 16, 16, 16, 16, 16,  7, 16, 16, 16, 16, 16,\n",
              "         9, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_y = [F.pad(torch.tensor(tokenizer_entities[i]), (0, maximum_tag_length-len(tokenizer_entities[i])), \"constant\", tag2idx[\"O\"]) for i in range(X.shape[0])]\n",
        "y = torch.stack(pre_y)\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1IBhxmtThyS",
        "outputId": "2da643e9-502d-4f9e-d242-ca0f8ec451c3"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([47959, 104])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_categorical = torch.stack([F.one_hot(y[0], num_classes=num_tags) for i in range(y.shape[0])])\n",
        "y_categorical.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKpaoIa4Tp7M",
        "outputId": "7c3bce64-1be0-4bc5-ca43-5d3932f1565c"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([47959, 104, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y_categorical, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "Jghi6ZetU0qf"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(X_train, y_train)\n",
        "test_ds = TensorDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "ZxM1vKQsVjl0"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n"
      ],
      "metadata": {
        "id": "HOH2p0ohVjpd"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a BiLSTM model for NER\n",
        "class BiLSTMForNER(nn.Module):\n",
        "    def __init__(self, num_words, num_tags, embedding_dim, hidden_dim=100, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        # Embedding layer that converts input words to embeddings\n",
        "        self.word_embeddings = nn.Embedding(num_words, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states with dimensionality hidden_dim.\n",
        "        # It will be bidirectional, meaning one LSTM for the forward pass and one for the backward pass.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, bidirectional=True, batch_first=True)\n",
        "\n",
        "        # The linear layer maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, num_tags)\n",
        "\n",
        "    def forward(self, sentence, hidden):\n",
        "        # Get the embeddings for the sentence\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        # Pass the embeddings through the LSTM; lstm_out shape is (len(sentence), batch_size, hidden_dim)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        # Pass the LSTM output through the linear layer to get the tag space\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "        # Convert the tag space to tag scores, which are log probabilities of the tags\n",
        "        tag_scores = torch.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (\n",
        "            weight.new(2*self.num_layers, batch_size, self.hidden_dim // 2).zero_().to(device),\n",
        "            weight.new(2*self.num_layers, batch_size, self.hidden_dim // 2).zero_().to(device)\n",
        "        )\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "WmAerTVhVjs0"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z1JGVp1x30AY"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTMForNER(num_words, num_tags, embedding_dim, hidden_dim, num_layers).to(device)\n"
      ],
      "metadata": {
        "id": "877hAFmB4lJK"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "aqa1-lovXv5m"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_divergence_loss(outputs, targets, tagset_size):\n",
        "    \"\"\"\n",
        "    Calculate the KL Divergence loss for the outputs with respect to the targets\n",
        "    \"\"\"\n",
        "    # Flatten outputs and targets to compute the distribution loss across all batches and classes\n",
        "    outputs = outputs.view(-1, tagset_size)\n",
        "    targets = targets.view(-1, tagset_size)\n",
        "    # Compute KL Divergence\n",
        "    kl_loss = F.kl_div(F.log_softmax(outputs, dim=1), F.softmax(targets.to(float), dim=1), reduction='batchmean')\n",
        "    return kl_loss"
      ],
      "metadata": {
        "id": "yQ7dA6gkYV-K"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, optimizer, num_tags, learning_rate, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        hidden = model.init_hidden(batch_size)\n",
        "        total_loss = 0\n",
        "        for sentences, tag_indices in train_dataloader:\n",
        "            sentences = sentences.to(device)\n",
        "            tag_indices = tag_indices.to(device)\n",
        "            # Clear the gradients before each instance\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            outputs, hidden = model(sentences, hidden)\n",
        "            loss = kl_divergence_loss(outputs, tag_indices, num_tags)\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            for hidden_state in hidden:\n",
        "              hidden_state.detach_()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")\n"
      ],
      "metadata": {
        "id": "D3-ZFBRX4soC"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_dl, optimizer, num_tags, learning_rate=lr, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmL_BS6FYkRN",
        "outputId": "65a2b5b6-5e52-4efd-ed9d-63d59adc1778"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0024895705788056696\n",
            "Epoch 2/10, Loss: 0.001997616343538338\n",
            "Epoch 3/10, Loss: 0.001617987942079435\n",
            "Epoch 4/10, Loss: 0.001173353546994676\n",
            "Epoch 5/10, Loss: 0.0007177031897923659\n",
            "Epoch 6/10, Loss: 0.0007289458718095877\n",
            "Epoch 7/10, Loss: 0.0005730376620197423\n",
            "Epoch 8/10, Loss: 0.0005998020456972916\n",
            "Epoch 9/10, Loss: 0.0005338901493125186\n",
            "Epoch 10/10, Loss: 0.0005248048226053383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix2tag = {ix: tag for tag, ix in tag2idx.items()}"
      ],
      "metadata": {
        "id": "FQO_F7D8uFvl"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax(iterable):\n",
        "    return max(enumerate(iterable), key=lambda x: x[1])[0]"
      ],
      "metadata": {
        "id": "p4iF9FY1uu25"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def evaluate_model(model, test_dataloader, ix_to_tag):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    true_tags = []\n",
        "    pred_tags = []\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    with torch.no_grad():\n",
        "        for sentence, tags in test_dataloader:\n",
        "            sentence = sentence.to(device)\n",
        "            tags = tags.to(device)\n",
        "            # Forward pass\n",
        "            tag_scores, hidden = model(sentence, hidden)\n",
        "            # Get the predicted tags\n",
        "            _, max_indices = torch.max(F.softmax(tag_scores, dim=1), dim=-1, keepdim=True)\n",
        "            one_hot = torch.zeros_like(F.softmax(tag_scores, dim=1))\n",
        "            one_hot.scatter_(-1, max_indices, 1)\n",
        "            # Update lists of true tags and predicted tags\n",
        "            true_tags.extend(tags.tolist())\n",
        "            pred_tags.extend(one_hot.tolist())\n",
        "    # Convert index sequences to tag name sequences\n",
        "\n",
        "\n",
        "    true_tag_names = [ix_to_tag[argmax(ix)] for ix in true_tags]\n",
        "    pred_tag_names = [ix_to_tag[argmax(ix)] if argmax(ix) < 17 else ix_to_tag[16] for ix in pred_tags ]\n",
        "\n",
        "    # Calculate and print the classification report\n",
        "    print(classification_report(true_tag_names, pred_tag_names))"
      ],
      "metadata": {
        "id": "DCyQIGqG6alm"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_dl, ix2tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e1rAVBAqz_V",
        "outputId": "c9eafb58-ddca-4cfd-fa5e-70a7831f17ce"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00         0\n",
            "       B-eve       1.00      0.97      0.98      4736\n",
            "       B-geo       0.00      0.00      0.00         0\n",
            "       B-gpe       0.00      0.00      0.00         0\n",
            "       B-nat       0.00      0.00      0.00         0\n",
            "       B-org       0.00      0.00      0.00         0\n",
            "       B-per       0.00      0.00      0.00         0\n",
            "       B-tim       0.00      0.00      0.00         0\n",
            "       I-art       0.00      0.00      0.00         0\n",
            "       I-eve       0.00      0.00      0.00         0\n",
            "       I-geo       0.00      0.00      0.00         0\n",
            "       I-gpe       0.00      0.00      0.00         0\n",
            "       I-nat       0.00      0.00      0.00         0\n",
            "       I-org       0.00      0.00      0.00         0\n",
            "       I-per       0.00      0.00      0.00         0\n",
            "       I-tim       0.00      0.00      0.00         0\n",
            "           O       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97      4736\n",
            "   macro avg       0.06      0.06      0.06      4736\n",
            "weighted avg       1.00      0.97      0.98      4736\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNgihwq_ugEW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}