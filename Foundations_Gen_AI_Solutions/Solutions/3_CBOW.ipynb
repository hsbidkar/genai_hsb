{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_jbFcxFZhG5K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6599f856-60a8-44b8-8b6c-9cd17b9fe564"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
      "Collecting pytorch-nlp\n",
      "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m90.1/90.1 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-nlp) (4.66.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
      "Installing collected packages: pytorch-nlp\n",
      "Successfully installed pytorch-nlp-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade  textblob gensim pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iklSJ4lqUQlT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed80acf8-969f-4ae0-be3b-457b37de1968"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import sys\n",
    "from textblob import TextBlob, Word\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import warnings\n",
    "import nltk\n",
    "\n",
    "TRACE = False  # Setting to true is useful when debugging to know which device is being used\n",
    "embedding_dim = 50\n",
    "epochs=100\n",
    "batch_size = 100\n",
    "BATCH = True\n",
    "\n",
    "def set_seeds_and_trace():\n",
    "  os.environ['PYTHONHASHSEED'] = '0'\n",
    "  np.random.seed(42)\n",
    "  random.seed(42)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "set_seeds_and_trace()\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "textblob_tokenizer = lambda x: TextBlob(x).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l13de14sclyD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cc137d3a-0f61-445c-a48c-2bf732a545b3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing get_data.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_data.sh\n",
    "if [ ! -f yelp.csv ]; then\n",
    "  wget -O yelp.csv https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PvRXU9EMVJMp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "004c49ae-55f1-43e7-d082-7241f93b838c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-11-27 17:16:50--  https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/xds4lua69b7okw8/yelp.csv [following]\n",
      "--2023-11-27 17:16:51--  https://www.dropbox.com/s/raw/xds4lua69b7okw8/yelp.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc6115ef95ba9873773a12939874.dl.dropboxusercontent.com/cd/0/inline/CIUtOK6uCYUaXV7QWzJPMq28_mX9CfngdnvDjxHYidJWFOvdO56rn7swzUnPjzSbBUJLP_FuOaIRoi60IsQhQSlQaCCDACW_nv5uVq6SwzX7mWIdrzfdRlA2Foto3lgShouC7RZAcY00CH4_Iy2o9UDt/file# [following]\n",
      "--2023-11-27 17:16:51--  https://uc6115ef95ba9873773a12939874.dl.dropboxusercontent.com/cd/0/inline/CIUtOK6uCYUaXV7QWzJPMq28_mX9CfngdnvDjxHYidJWFOvdO56rn7swzUnPjzSbBUJLP_FuOaIRoi60IsQhQSlQaCCDACW_nv5uVq6SwzX7mWIdrzfdRlA2Foto3lgShouC7RZAcY00CH4_Iy2o9UDt/file\n",
      "Resolving uc6115ef95ba9873773a12939874.dl.dropboxusercontent.com (uc6115ef95ba9873773a12939874.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
      "Connecting to uc6115ef95ba9873773a12939874.dl.dropboxusercontent.com (uc6115ef95ba9873773a12939874.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8091185 (7.7M) [text/plain]\n",
      "Saving to: ‘yelp.csv’\n",
      "\n",
      "yelp.csv            100%[===================>]   7.72M  10.3MB/s    in 0.8s    \n",
      "\n",
      "2023-11-27 17:16:52 (10.3 MB/s) - ‘yelp.csv’ saved [8091185/8091185]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash get_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QAWXcLEieD4E"
   },
   "outputs": [],
   "source": [
    "path = './yelp.csv'\n",
    "yelp = pd.read_csv(path)\n",
    "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "X = yelp_best_worst.text\n",
    "y = yelp_best_worst.stars.map({1:0, 5:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ljgSnKkzeM4-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "710e0a9d-012c-4129-b0e3-5667151221ff"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "0     9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1     ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2     6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3     _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4     6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "...                      ...         ...                     ...    ...   \n",
       "9995  VY_tvNUCCXGXQeSvJl757Q  2012-07-28  Ubyfp2RSDYW0g7Mbr8N3iA      3   \n",
       "9996  EKzMHI1tip8rC1-ZAy64yg  2012-01-18  2XyIOQKbVFb6uXQdJ0RzlQ      4   \n",
       "9997  53YGfwmbW73JhFiemNeyzQ  2010-11-16  jyznYkIbpqVmlsZxSDSypA      4   \n",
       "9998  9SKdOoDHcFoxK5ZtsgHJoA  2012-12-02  5UKq9WQE1qQbJ0DJbc-B6Q      2   \n",
       "9999  pF7uRzygyZsltbmVpjIyvw  2010-10-16  vWSmOhg2ID1MNZHaWapGbA      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "0     My wife took me here on my birthday for breakf...  review   \n",
       "1     I have no idea why some people give bad review...  review   \n",
       "2     love the gyro plate. Rice is so good and I als...  review   \n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4     General Manager Scott Petello is a good egg!!!...  review   \n",
       "...                                                 ...     ...   \n",
       "9995  First visit...Had lunch here today - used my G...  review   \n",
       "9996  Should be called house of deliciousness!\\n\\nI ...  review   \n",
       "9997  I recently visited Olive and Ivy for business ...  review   \n",
       "9998  My nephew just moved to Scottsdale recently so...  review   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "0     rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1     0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2     0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3     uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4     vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "...                      ...   ...     ...    ...  \n",
       "9995  _eqQoPtQ3e3UxLE4faT6ow     1       2      0  \n",
       "9996  ROru4uk5SaYc3rg8IU7SQw     0       0      0  \n",
       "9997  gGbN1aKQHMgfQZkqlsuwzg     0       0      0  \n",
       "9998  0lyVoNazXa20WzUyZPLaQQ     0       0      0  \n",
       "9999  KSBFytcdjPKZgXKQnYQdkA     0       0      0  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-6cb7447b-d9e2-4654-97eb-0aef3726139c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>VY_tvNUCCXGXQeSvJl757Q</td>\n",
       "      <td>2012-07-28</td>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>_eqQoPtQ3e3UxLE4faT6ow</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>EKzMHI1tip8rC1-ZAy64yg</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>ROru4uk5SaYc3rg8IU7SQw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>53YGfwmbW73JhFiemNeyzQ</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>gGbN1aKQHMgfQZkqlsuwzg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9SKdOoDHcFoxK5ZtsgHJoA</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>0lyVoNazXa20WzUyZPLaQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pF7uRzygyZsltbmVpjIyvw</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cb7447b-d9e2-4654-97eb-0aef3726139c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6cb7447b-d9e2-4654-97eb-0aef3726139c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6cb7447b-d9e2-4654-97eb-0aef3726139c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-81ce950e-a9c4-40b7-a0eb-5b307c78dc7a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81ce950e-a9c4-40b7-a0eb-5b307c78dc7a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-81ce950e-a9c4-40b7-a0eb-5b307c78dc7a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_1327aa81-068d-4abf-aca0-965049b030f3\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('yelp')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_1327aa81-068d-4abf-aca0-965049b030f3 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('yelp');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dUlTe1xsgi51",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7f2850ba-64c4-44c7-ebce-3d6669bead4f"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TextBlob(\"By wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our witness was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
       "\n",
       "To yourself a favor and get their Bloody Mary.  It was phenomena and simply the best I've ever had.  I'm pretty sure they only use ingredient from their garden and blend them fresh when you order it.  It was amazing.\n",
       "\n",
       "While EVERYTHING on the menu looks excellent, I had the white ruffle scrambled eggs vegetable skilled and it was taste and delicious.  It came with 2 pieces of their grizzled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
       "\n",
       "Anyway, I can't wait to go back!\")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "TextBlob(X.values[0]).correct()"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "3OgH8jUM7XvU"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bfR6qIZZhIHd"
   },
   "outputs": [],
   "source": [
    "# Create corpus of sentences such that the sentence has more than 3 words\n",
    "corpus = [line for line in X.values if len(TextBlob(line).words)> 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2B_z5Udki-_s",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a59923f6-6b80-4ed0-cef9-b51948c382c8"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!',\n",
       " 'I have no idea why some people give bad reviews about this place. It goes to show you, you can please everyone. They are probably griping about something that their own fault...there are many people like that.\\n\\nIn any case, my friend and I arrived at about 5:50 PM this past Sunday. It was pretty crowded, more than I thought for a Sunday evening and thought we would have to wait forever to get a seat but they said we\\'ll be seated when the girl comes back from seating someone else. We were seated at 5:52 and the waiter came and got our drink orders. Everyone was very pleasant from the host that seated us to the waiter to the server. The prices were very good as well. We placed our orders once we decided what we wanted at 6:02. We shared the baked spaghetti calzone and the small \"Here\\'s The Beef\" pizza so we can both try them. The calzone was huge and we got the smallest one (personal) and got the small 11\" pizza. Both were awesome! My friend liked the pizza better and I liked the calzone better. The calzone does have a sweetish sauce but that\\'s how I like my sauce!\\n\\nWe had to box part of the pizza to take it home and we were out the door by 6:42. So, everything was great and not like these bad reviewers. That goes to show you that  you have to try these things yourself because all these bad reviewers have some serious issues.']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_Z1eJZrhK7K",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At this point we have a list (any iterable will do) of queries that are longer than 3 words. This is normal to filter random queries. Now we must use the `LabelEncoder` object to `fit` on the corpus, in order to convert each wor to an ID, and later convert such corpus of list of words into their identifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CHtu75Kpi6XF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f36e5445-f62c-42d5-f962-591efe128461"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before the tokenizer: ['My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!']\n",
      "After the tokenizer: [tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  13,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  13,  30,  11,  31,  32,  33,  34,   6,  35,  36,  37,  38,\n",
      "         39,  40,  41,  35,  42,  43,  44,  45,  34,  46,  35,  47,  48,  49,\n",
      "          5,  35,  50,  51,  52,  53,  54,  11,  49,  23,  55,  56,  39,  13,\n",
      "         57,  11,  58,  35,  59,  60,  61,  62,  63,  45,  64,  65,  66,  67,\n",
      "         68,  69,  23,  70,  11,  71,  72,  73,  74,  48,  75,  76,  39,  13,\n",
      "         77,  78,  79,   6,  35,  80,  81,  82,  83,  84,  35,  85,  86,  87,\n",
      "         88,  89,  90,  11,  12,  13,  91,  11,  92,  39,  93,  94,  95,  96,\n",
      "         97,  23,  98,  99,  94,  13, 100,  11,  12, 101,  19,  35, 102, 103,\n",
      "         39,  13,  35,  59, 104,  60,  61,  62, 105,  83, 106, 107, 108, 109,\n",
      "        110])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# tokenizer = Tokenizer()\n",
    "# # Use the fit_on_texts method to fit the tokenizer\n",
    "# tokenizer.fit_on_texts(corpus) # Fill\n",
    "\n",
    "print(f'Before the tokenizer: {corpus[:1]}')\n",
    "\n",
    "#Now use the same \"trained\" tokenizer to convert the corpus from words to IDs with the texts_to_sequences method\n",
    "tokenized_corpus = [ids_from_words.batch_encode(sentence.split()) for sentence in corpus]\n",
    "\n",
    "print(f'After the tokenizer: {tokenized_corpus[:1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "g44ICdUcj7ZL"
   },
   "outputs": [],
   "source": [
    "vocab_size = LabelEncoder.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qTM2wqbzke5n",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "01625e9d-07ab-429b-9ad5-ef069f4c679a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First 5 corpus items are [tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  13,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  13,  30,  11,  31,  32,  33,  34,   6,  35,  36,  37,  38,\n",
      "         39,  40,  41,  35,  42,  43,  44,  45,  34,  46,  35,  47,  48,  49,\n",
      "          5,  35,  50,  51,  52,  53,  54,  11,  49,  23,  55,  56,  39,  13,\n",
      "         57,  11,  58,  35,  59,  60,  61,  62,  63,  45,  64,  65,  66,  67,\n",
      "         68,  69,  23,  70,  11,  71,  72,  73,  74,  48,  75,  76,  39,  13,\n",
      "         77,  78,  79,   6,  35,  80,  81,  82,  83,  84,  35,  85,  86,  87,\n",
      "         88,  89,  90,  11,  12,  13,  91,  11,  92,  39,  93,  94,  95,  96,\n",
      "         97,  23,  98,  99,  94,  13, 100,  11,  12, 101,  19,  35, 102, 103,\n",
      "         39,  13,  35,  59, 104,  60,  61,  62, 105,  83, 106, 107, 108, 109,\n",
      "        110]), tensor([ 83, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,  39,\n",
      "        123, 108, 124, 125,  48, 126, 127, 128, 129, 130, 131, 132, 120, 133,\n",
      "        134,  23, 135, 136, 130, 137, 116,  41, 138, 139, 140, 141,   7, 142,\n",
      "         11,  83,  33, 143, 120, 144, 145, 121, 146, 147,  39,  13,  45, 148,\n",
      "        149, 150,  83, 151,   9,  53, 152, 153,  11, 151, 154, 155, 111, 108,\n",
      "        107, 156, 108,  49,  53, 157, 158,  65, 159, 160, 161, 162,  74,  35,\n",
      "        163, 164, 165,  69, 166, 167, 168, 169, 170, 162, 143, 171,  11,  35,\n",
      "        172,  93,  11, 173,  31, 174, 175, 176,  13, 177, 178,  69,  35, 179,\n",
      "        134, 162, 180, 108,  35, 172, 108,  35, 181,  15, 182, 170, 177, 183,\n",
      "        184, 185, 169, 186,  31, 187, 188, 154, 189, 190, 154, 191, 143, 192,\n",
      "        169, 193,  35, 194, 195, 196,  11,  35, 197, 198,  15, 199, 200,  46,\n",
      "        154, 126, 201, 202, 203,  15, 196,  13, 204,  11, 154, 173,  35, 205,\n",
      "        206, 207,  11, 173,  35, 197, 208, 209, 210, 170, 211,   1, 142, 212,\n",
      "         35, 200, 213,  11,  83, 212,  35, 196,  50,  15, 196, 214, 111,  53,\n",
      "        215, 216, 158, 217, 218,  83,  41,   7, 219, 169,  84, 108, 220, 221,\n",
      "         97,  35, 200, 108, 222,  12, 223,  11, 154, 170, 224,  35, 225, 226,\n",
      "        227, 228, 229,  13, 230,  11, 231,  41, 232, 118, 233, 234, 123, 108,\n",
      "        124,  48, 134,  48, 111, 108, 202, 232, 235,  52, 236, 237, 232, 118,\n",
      "        238, 111, 115, 239, 240]), tensor([241, 242,  11,  83, 243, 244, 245, 246, 247, 177, 248,  11, 249, 226,\n",
      "         53, 250,  97, 251,  53, 252, 253, 254, 255, 256,  11,  53, 257,  94,\n",
      "        258,  15, 259, 260,  11, 261, 262, 214,  53, 263, 264,  97, 265,  35,\n",
      "        266, 267,  11, 268, 269, 126, 270, 271, 272,  11, 273,  44, 274, 275,\n",
      "        237, 276,  35, 266,  11, 277,  15, 278, 279, 280, 281, 204, 108, 282,\n",
      "         35, 283, 284, 285,  11, 286]), tensor([287, 288, 289, 290, 281,  53, 183, 291, 292, 108, 109, 293, 294, 158,\n",
      "        282,   4, 295,  48, 296,  48, 111, 140, 297, 298, 299, 300,  94, 289,\n",
      "         11, 301,  35, 302,  94, 115, 303, 184,  48, 304, 305, 306,  11, 307,\n",
      "        161, 308, 296,  48, 309, 310, 224, 311, 312, 184,  83, 313, 314, 315,\n",
      "         83, 316, 317, 318, 130, 319, 320, 218, 154, 321,  69,  72, 134, 281,\n",
      "        322, 323, 108, 289,  11, 324, 325, 326, 327, 173,  53, 328,   9, 329,\n",
      "        330, 331]), tensor([332, 190, 333, 334,  11, 335, 336, 337,  83, 338,   5,  83,  84, 108,\n",
      "        109, 165,  35, 339, 340,   9, 341,  15,  32, 281, 134, 342, 343, 344,\n",
      "        345, 346, 347, 348, 111, 349, 350, 351, 296,  83, 352, 353, 354, 355,\n",
      "        356, 357, 108, 358, 359,  78, 360, 108, 361, 362, 363, 364,  35, 365,\n",
      "        366, 367, 368,   7, 369,  11,   7, 345, 370, 371, 372,   9, 373, 374,\n",
      "        375,  42, 108, 376,  39,  40, 377,  69,  35,  21, 158,  74,  83, 378,\n",
      "         35, 225,  83,  13, 379, 143, 380, 226,  35, 381, 382,  11, 383, 384,\n",
      "         83, 385, 386,   9, 387, 108, 388,  15,  80,  13, 389,  83, 390, 391,\n",
      "        237,  35, 392, 393, 394, 395, 396, 397, 398, 399, 279, 400, 401,  39,\n",
      "         19,  12, 402, 108, 403, 404, 405, 190,  60,  84,  46, 406, 407, 408,\n",
      "        409, 410,  11, 411, 412, 413, 414, 415, 129, 130, 201, 170, 177, 416,\n",
      "        417, 158,  35, 418, 419, 420,  35, 421, 422, 423, 424,  83, 425, 115,\n",
      "        426,  69,   7, 427, 428,  11, 396, 396, 429, 430, 431,  53, 432,  15,\n",
      "        433, 434, 281, 435,  83, 436, 437, 438,  83,  13, 439, 108, 202,  35,\n",
      "        440, 433, 158,  12,  13, 441, 442, 279, 443,  12, 237, 444, 158,  63,\n",
      "         53, 445, 446,  74,  12, 164, 108, 447, 448,  15, 449, 281, 450,  11,\n",
      "         92, 129, 451, 452,  11, 115, 453, 279, 454, 441,  18, 281,  53, 455,\n",
      "        456, 457, 296,  35, 183,  32, 458, 459, 108, 460,   4, 276,  35, 461,\n",
      "        279, 121, 462, 463, 464,  63,  53, 465,   9, 466, 467, 461,  11, 468,\n",
      "        469, 281,   7, 470, 471,  53, 472,  97, 473,  11, 474, 475, 276,  35,\n",
      "        433, 476, 320,  77, 477,  35, 478, 130, 479, 480,  35, 481])]\n",
      "Length of corpus is 4056\n"
     ]
    }
   ],
   "source": [
    "print(f'First 5 corpus items are {tokenized_corpus[:5]}')\n",
    "print(f'Length of corpus is {len(tokenized_corpus)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GR97HVOqkoMI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ade7b16d-1a68-4494-97ab-220258350bcd"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "type(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def ids_from_text(text):\n",
    "  return ids_from_words.batch_encode(text)\n",
    "\n",
    "def text_from_ids(ids):\n",
    "  return ids_from_words.batch_decode(ids)"
   ],
   "metadata": {
    "id": "f6B_A4TL9awJ"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def pad_sequence_of_tokens(x, maxlen, unk_token='UNK'):\n",
    "  if len(x)<maxlen:\n",
    "    x.extend([unk_token]*(maxlen-len(x)))\n",
    "  return x"
   ],
   "metadata": {
    "id": "IEtqKkd9_ZmZ"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SvMp9eWsk2Z-"
   },
   "outputs": [],
   "source": [
    "# This is the algorithmic part of batching the dataset and yielding the window of words and expected middle word for each bacth as a generator.\n",
    "def create_context_target_pairs(texts, context_size):\n",
    "    data = []\n",
    "    for text in texts:\n",
    "        tokens = text.split()\n",
    "        for i, word in enumerate(tokens):\n",
    "            start = max(0, i - context_size)\n",
    "            end = min(len(tokens), i + context_size + 1)\n",
    "            context = pad_sequence_of_tokens([tokens[j] for j in range(start, end) if j != i], maxlen=4)\n",
    "            target = ids_from_words.token_to_index[word]\n",
    "            context_indices = [ids_from_words.token_to_index[w] for w in context]\n",
    "            context_indices.append(target)\n",
    "            data.append(torch.Tensor(context_indices))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0dw_S7Kk6lW",
    "outputId": "ce29f09a-b1b5-4cc1-d432-3963bde9cf3d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice now in a sample how we construct X and y to predict words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JCmSyCj8k6He"
   },
   "outputs": [],
   "source": [
    "data = create_context_target_pairs(corpus[:500], 2)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = torch.stack(data)"
   ],
   "metadata": {
    "id": "WsntEC8p-2Xj"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X = data[:, :4].to(torch.long)\n",
    "y = data[:, 4].to(torch.long)"
   ],
   "metadata": {
    "id": "TOoN-ej4AMQI"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X"
   ],
   "metadata": {
    "id": "Hfz_UgdkAVVx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "80c40879-b27c-4795-f6c0-bd39649b280b"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[    2,     3,     0,     0],\n",
       "        [    1,     3,     4,     0],\n",
       "        [    1,     2,     4,     5],\n",
       "        ...,\n",
       "        [   11,    35, 11658,   138],\n",
       "        [   35,    32,   138,     0],\n",
       "        [   32, 11658,     0,     0]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wjvrCdY5lkJk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1c0f3b12-2781-44c5-d64e-7d41055a363f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([61653, 4])\n",
      "torch.Size([61653])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cIBBOa4a6qM"
   },
   "source": [
    "Now comes the core part, defining the model. Keras provides a convenient Sequential model class to just `add` layers of any type and they will just work. Let's add an `Embedding` layer (that will map the word ids into a vector of size 100), a `Lambda` to average the words out in a sentence, and a `Dense layer` to select the best word on the other end. This is classic CBOW.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NjtywT2Fa6qM"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        print((vocab_size, embedding_dim))\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Linear layer to act as the hidden layer\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        # Linear layer to predict the center word\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        embeds = torch.mean(embeds, dim=1)\n",
    "        out = torch.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = torch.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bBNNSCeYa6qM"
   },
   "outputs": [],
   "source": [
    "def train_cbow(X, y, model, loss_function, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        # Step 1. Recall that torch *accumulates* gradients. Before passing in a new instance,\n",
    "        # you need to zero out the gradients from the old instance\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Step 2. Run the forward pass, getting log probabilities over next words\n",
    "        log_probs = model(X)\n",
    "\n",
    "        # Step 3. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, y)\n",
    "\n",
    "        # Step 4. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('Epoch: {}, Loss: {:.4f}'.format(epoch + 1, total_loss))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "mpEmERLpa6qM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f3eb1bce-a0ac-4994-b08d-23b8a4ae207a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(45224, 50)\n"
     ]
    }
   ],
   "source": [
    "context_size=2\n",
    "embedding_dim=50\n",
    "vocab_size = len(ids_from_words.vocab)\n",
    "model = CBOW(vocab_size, embedding_dim, context_size * 2)\n",
    "model.to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "X = X.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trained_model = train_cbow(X, y, model, loss_function, optimizer, epochs=100)"
   ],
   "metadata": {
    "id": "PSi6tkuJA2l2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "946869a8-931f-43af-e17a-4bb86c08f067"
   },
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 10, Loss: 10.7353\n",
      "Epoch: 20, Loss: 10.7351\n",
      "Epoch: 30, Loss: 10.7349\n",
      "Epoch: 40, Loss: 10.7347\n",
      "Epoch: 50, Loss: 10.7344\n",
      "Epoch: 60, Loss: 10.7342\n",
      "Epoch: 70, Loss: 10.7340\n",
      "Epoch: 80, Loss: 10.7338\n",
      "Epoch: 90, Loss: 10.7336\n",
      "Epoch: 100, Loss: 10.7334\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "QacFd_6Da6qN"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "embeddings = trained_model.embeddings.weight.data.cpu().numpy()\n",
    "\n",
    "# Now, we need to save these embeddings in a format that gensim can understand\n",
    "# For that, we will use the KeyedVectors instance in gensim\n",
    "\n",
    "# Instantiate the KeyedVectors with the correct size\n",
    "kv = KeyedVectors(vector_size=embeddings.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Add the vectors and their corresponding words to the KeyedVectors instance\n",
    "kv.add_vectors(ids_from_words.index_to_token, embeddings)"
   ],
   "metadata": {
    "id": "z1fC32QFHIWF"
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MsEzF8O1a6qN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "853d2efb-48a3-4f32-84c5-ef193988f7bb"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('dated', 0.5481334924697876),\n",
       " ('emerald', 0.5394065976142883),\n",
       " ('Betitos', 0.5250834822654724),\n",
       " ('wicked', 0.5036346316337585),\n",
       " ('agreed', 0.4864133894443512),\n",
       " ('else.\"', 0.4845808446407318),\n",
       " ('Chutney', 0.4819386899471283),\n",
       " ('side!', 0.47849413752555847),\n",
       " ('it),', 0.4752046763896942),\n",
       " ('Yard', 0.47150516510009766)]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "kv.most_similar(positive=['gasoline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qDAAzHMka6qN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9e88afe7-4131-493f-f808-3fdafcba1cb7"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('(though', 0.538329005241394),\n",
       " ('install!!', 0.5372428894042969),\n",
       " ('coolness', 0.5159246325492859),\n",
       " ('flavors!', 0.5054166913032532),\n",
       " ('FORTY-FIVE', 0.505184531211853),\n",
       " ('quiche,', 0.5023967623710632),\n",
       " (\"Fry's\", 0.4885081946849823),\n",
       " ('rotate', 0.4879502058029175),\n",
       " ('fresh!!', 0.48583441972732544),\n",
       " ('sinful', 0.4754049479961395)]"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "kv.most_similar(negative=['apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    },
    "id": "p_wQsdlCa6qO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "6uCMkd6qbRxk"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuClass": "premium"
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}